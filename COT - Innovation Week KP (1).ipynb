{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJ5caKL2Ff2B"
   },
   "source": [
    "#Â Advanced Prompting: Chain of Thought (adapted for Innovation Week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dMkREhcA-Rtw"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GC1b7po9xWM6"
   },
   "source": [
    "## Credits\n",
    "\n",
    "**Please check the [original notebook](https://github.com/GoogleCloudPlatform/applied-ai-engineering-samples/blob/main/assets/advanced_prompting_training/cot_react.ipynb), created by by Michael W. Sherman, for many more indications than the ones in this notebook**. I (Elena Mata Yandiola) condensed the original -brilliant- notebook in order to make it suitable to GCC's Innovation Week.\n",
    "\n",
    "**Note: This notebook has been adapted to be run in Vertex Workbench.** If you want to run it locally, or in Colab, you will need some additional cells, e.g. for authentication (they can be found in the original notebook above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GC1b7po9xWM6"
   },
   "source": [
    "## Setup -- Run This Code First!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NZ_4h24m-B8u",
    "outputId": "639a80ce-26a2-47e3-c992-b3032338d33b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Tested with these package versions.Note this notebook uses matplotlib.pyplot.\n",
    "!pip install --q --user google-cloud-aiplatform==1.35.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAKE SURE TO RESTART YOUR RUNTIME BEFORE CONTINUING\n",
    "\n",
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True) #automatically restarts kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bSeWZt3ZpxeY"
   },
   "source": [
    "Set your Google Cloud project ID in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mLDEjCVzp7eh"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"testing-elena\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "# Code examples may misbehave if the model is changed.\n",
    "MODEL_NAME = \"text-bison@001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2fTAg64qFY2B"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 14:30:03.547792: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Set up Vertex PaLM API.\n",
    "import vertexai\n",
    "from vertexai.language_models import TextGenerationModel\n",
    "\n",
    "vertexai.init(project=PROJECT_ID,\n",
    "              location=LOCATION)\n",
    "parameters = {\n",
    "    \"temperature\": 0,\n",
    "    \"max_output_tokens\": 1024,\n",
    "    \"top_p\": 0.8,\n",
    "    \"top_k\": 40\n",
    "}\n",
    "\n",
    "model = TextGenerationModel.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSpDXdhBvhtu"
   },
   "source": [
    "This function is used throughout the notebook to show the full LLM call and the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "esxRVsLAvvr6"
   },
   "outputs": [],
   "source": [
    "def call_llm(model, parameters, llm_call, show_activity = True):\n",
    "  response = model.predict(llm_call, **parameters).text\n",
    "\n",
    "  if show_activity:\n",
    "    BOLD = \"\\033[1m\"\n",
    "    UNFORMAT = \"\\033[0m\\x1B[0m\"\n",
    "    print(f\"{BOLD}The call to the LLM:{UNFORMAT}\\n{llm_call}\\n\")\n",
    "    print(f\"{BOLD}The response:{UNFORMAT}\")\n",
    "    print(response)\n",
    "\n",
    "  return response  # Return to `_` if not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qoiMSEJoY9gt"
   },
   "outputs": [],
   "source": [
    "# Wrap code cell output to improve notebook readability.\n",
    "# Source: https://stackoverflow.com/questions/58890109/line-wrapping-in-collaboratory-google-results/61401455#61401455\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def set_css():\n",
    "  display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))\n",
    "get_ipython().events.register('pre_run_cell', set_css)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "US-jQm1MuGBa"
   },
   "source": [
    "# Chain-of-Thought Prompting\n",
    "\n",
    "To LLMs, chains are more than a fashionable accessory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82YfCjFJVX60"
   },
   "source": [
    "## Overview\n",
    "\n",
    "In chain-of-thought prompting, you provide one- or few-shot exemplars showing the reasoning steps to get to a desired output. This is different from standard one- or few-shot prompting, where your exemplars show only the input and the correct output.\n",
    "\n",
    "The reasoning breakdown you provide in chain-of-thought exemplars is similar to the natural language internal monologue a person has as they think through a problem or task.\n",
    "\n",
    "If \"internal monologue\" is a strange concept, think about how you verbalize your thoughts to solve a problem or accomplish a task. For example, you're cooking dinner:\n",
    "\n",
    " ```Ok I've chopped the celery. Now I need to get started on the chicken. Is the oven on? Let me start preheating the oven. Wait, what temperature? I need to check the recipe again...```\n",
    "\n",
    "This \"internal monologue\" or \"inner speech\" facilitates applying problem solving patterns to new problems we haven't seen before, by identifying what should happen next to make progress on the task.\n",
    "\n",
    "By calling the LLM with exemplars that include an \"internal monologue\" of text reasoning, the LLM produces responses that include similar text reasoning. Having the LLM generate the reasoning text as part of the response increases the chance the response ends with the desired output.\n",
    "\n",
    "The reasoning steps in the response\n",
    " also provide interpretability of how the LLM arrived at the final output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydRfjsuBI5Ip",
    "tags": []
   },
   "source": [
    "## Chain of Thought Basics\n",
    "\n",
    "Math word problems are a good chain-of-thought demonstration, since they are simple mathematically and logically but require multiple steps of reasoning.\n",
    "\n",
    "In this example (from the Chain of Thought [paper](https://arxiv.org/pdf/2201.11903.pdf)) note the incorrect answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "0VJcAD7lYXE0",
    "outputId": "188ae075-ff00-4a5b-fca2-b40ec449a777"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe call to the LLM:\u001b[0m\u001b[0m\n",
      "Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls.\n",
      "Each can has 3 tennis balls. How many tennis balls does he have now?\n",
      "A: The answer is 11.\n",
      "Q: The cafeteria had 23 apples.\n",
      "If they used 20 to make lunch and bought 6 more, how many apples do they have?\n",
      "A:\n",
      "\n",
      "\u001b[1mThe response:\u001b[0m\u001b[0m\n",
      "The answer is 19.\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls.\n",
    "Each can has 3 tennis balls. How many tennis balls does he have now?\n",
    "A: The answer is 11.\n",
    "Q: The cafeteria had 23 apples.\n",
    "If they used 20 to make lunch and bought 6 more, how many apples do they have?\n",
    "A:\"\"\"\n",
    "\n",
    "_ = call_llm(model, parameters, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vmzEro2Z707"
   },
   "source": [
    "Rewriting the exemplar to include a chain of thought shows the LLM how to decompose the question into multiple simple steps of reasoning.\n",
    "\n",
    "The model response then follows a similar chain of thought, increasing the likelihood of a correct answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "X_QojLuvZzLV",
    "outputId": "9f88591f-1f86-4092-8d22-63a875cb0df0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe call to the LLM:\u001b[0m\u001b[0m\n",
      "Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls.\n",
      "Each can has 3 tennis balls. How many tennis balls does he have now?\n",
      "A: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. \n",
      "The answer is 11.\n",
      "\n",
      "Q: The cafeteria had 23 apples.\n",
      "If they used 20 to make lunch and bought 6 more, how many apples do they have?\n",
      "A:\n",
      "\n",
      "\u001b[1mThe response:\u001b[0m\u001b[0m\n",
      "The cafeteria started with 23 apples. They used 20 apples to make lunch, so they have 23 - 20 = 3 apples left. They bought 6 more apples, so they now have 3 + 6 = 9 apples. \n",
      "The answer is 9.\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls.\n",
    "Each can has 3 tennis balls. How many tennis balls does he have now?\n",
    "A: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. \n",
    "The answer is 11.\n",
    "\n",
    "Q: The cafeteria had 23 apples.\n",
    "If they used 20 to make lunch and bought 6 more, how many apples do they have?\n",
    "A:\"\"\"\n",
    "\n",
    "_ = call_llm(model, parameters, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjwgFMOLaem9"
   },
   "source": [
    "Notice the chain of thought includes both text describing the steps to follow and intermediate outputs/conclusions from each reasoning step.\n",
    "\n",
    "Try experimenting with different questions by changing the `question` variable in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "Fd4e62T7aWoG",
    "outputId": "6861171f-a05a-4606-af7a-b959dd67b4bb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe call to the LLM:\u001b[0m\u001b[0m\n",
      "Q: Roger has 5 tennis balls.\n",
      "He buys 2 more cans of tennis balls.\n",
      "Each can has 3 tennis balls. How many tennis balls does he have now?\n",
      "A: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11.\n",
      "Q: Nomfundo writes legal briefs.\n",
      "Each brief has 3 sections, each section takes 4 hours.\n",
      "She wrote 3 briefs this week. How long did it take?\n",
      "A:\n",
      "\n",
      "\u001b[1mThe response:\u001b[0m\u001b[0m\n",
      "Each brief has 3 sections, each section takes 4 hours, so 3 sections * 4 hours = 12 hours. She wrote 3 briefs, so 12 hours * 3 = 36 hours. The answer is 36.\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"Nomfundo writes legal briefs.\n",
    "Each brief has 3 sections, each section takes 4 hours.\n",
    "She wrote 3 briefs this week. How long did it take?\"\"\"\n",
    "\n",
    "one_shot_exemplar = \"\"\"Q: Roger has 5 tennis balls.\n",
    "He buys 2 more cans of tennis balls.\n",
    "Each can has 3 tennis balls. How many tennis balls does he have now?\n",
    "A: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11.\n",
    "Q: \"\"\"\n",
    "\n",
    "# Prepending the one shot exemplar before the question we want answered.\n",
    "llm_call = f\"{one_shot_exemplar}{question}\\nA:\"\n",
    "_ = call_llm(model, parameters, llm_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XUp7beLcQsS"
   },
   "source": [
    "The LLM response will usually mimic the reasoning style in the exemplars. This means **you'll get the best performance if the chain of thought reasoning in your exemplars is a good fit for the task**.\n",
    "\n",
    "Compare the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "id": "BPQVYIPucnkF",
    "outputId": "42377444-7537-4300-bcb7-a92bd896565f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe call to the LLM:\u001b[0m\u001b[0m\n",
      "Q: Roger has 5 tennis balls.\n",
      "He buys 2 more cans of tennis balls.\n",
      "Each can has 3 tennis balls. How many tennis balls does he have now?\n",
      "A: Roger started with 5 balls. 2 cans of 3 tennis balls\n",
      "each is 6 tennis balls. 5 + 6 = 11. The answer is 11.\n",
      "Q: A high efficiency factory produces 100 units per day.\n",
      "A medium efficiency factory produces 60 units per day.\n",
      "A low efficiency factory produces 30 units per day.\n",
      "Megacorp owns 5 factories. 3 are high efficiency, 2 are low efficiency.\n",
      "Tomorrow they reconfigure a low efficiency factory up to medium efficiency.\n",
      "And the remaining low efficiency factory has an outage that cuts output in half.\n",
      "How many units can they produce today? How many tomorrow?\n",
      "A:\n",
      "\n",
      "\u001b[1mThe response:\u001b[0m\u001b[0m\n",
      "Today, the 3 high efficiency factories produce 3 * 100 = 300 units.\n",
      "The 2 low efficiency factories produce 2 * 30 = 60 units.\n",
      "So today, Megacorp produces 300 + 60 = 360 units.\n",
      "Tomorrow, the reconfigured low efficiency factory produces 60 units.\n",
      "The remaining low efficiency factory produces 30 / 2 = 15 units.\n",
      "So tomorrow, Megacorp produces 60 + 15 = 75 units.\n",
      "The answer is 360, 75.\n"
     ]
    }
   ],
   "source": [
    "# Correct answer: 360, 375.\n",
    "question = \"\"\"A high efficiency factory produces 100 units per day.\n",
    "A medium efficiency factory produces 60 units per day.\n",
    "A low efficiency factory produces 30 units per day.\n",
    "Megacorp owns 5 factories. 3 are high efficiency, 2 are low efficiency.\n",
    "Tomorrow they reconfigure a low efficiency factory up to medium efficiency.\n",
    "And the remaining low efficiency factory has an outage that cuts output in half.\n",
    "How many units can they produce today? How many tomorrow?\"\"\"\n",
    "\n",
    "one_shot_exemplar = \"\"\"Q: Roger has 5 tennis balls.\n",
    "He buys 2 more cans of tennis balls.\n",
    "Each can has 3 tennis balls. How many tennis balls does he have now?\n",
    "A: Roger started with 5 balls. 2 cans of 3 tennis balls\n",
    "each is 6 tennis balls. 5 + 6 = 11. The answer is 11.\n",
    "Q: \"\"\"\n",
    "\n",
    "llm_call = f\"{one_shot_exemplar}{question}\\nA:\"\n",
    "_ = call_llm(model, parameters, llm_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJ6Xo0gwpi35"
   },
   "source": [
    "Note the mistake in the output. The LLM response fails to account for the 3 high efficiency factories that are still running tomorrow.\n",
    "\n",
    "For this task, it's better to use a chain of thought with reasoning steps that include a connection to different units of measurement (tennis ball can sizes vs. factory outputs) along with a carrying over of counts between days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "id": "ThikEZV1cNYM",
    "outputId": "5f3249ea-d624-4777-9729-00b58a6ab509"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe call to the LLM:\u001b[0m\u001b[0m\n",
      "Q: A large tennis ball can has 5 balls.\n",
      "A small tennis ball can has 3 balls.\n",
      "Roger has 3 large cans and 2 small cans today.\n",
      "Tomorrow he wins a bet and turns one small can into a large can.\n",
      "How many balls does he have today? How many tomorrow?\n",
      "A: 3 large cans is 3 * 5 = 15 tennis balls.\n",
      "2 small cans is 2 * 3 = 6 tennis balls.\n",
      "Today Roger has 15 + 6 = 21 tennis balls.\n",
      "Tomorrow's trade means losing one small tennis ball can and gaining a large can.\n",
      "Roger still has the cans he had yesterday.\n",
      "2 small cans from yesterday - 1 = 1 small can\n",
      "3 large cans from yesterday + 1 = 4 large cans\n",
      "4 large cans is 4 * 5 = 20 tennis balls.\n",
      "1 small can is 1 * 3 tennis balls.\n",
      "Tomorrow Roger has 20 + 3 = 23 tennis balls.\n",
      "Q: A high efficiency factory produces 100 units per day.\n",
      "A medium efficiency factory produces 60 units per day.\n",
      "A low efficiency factory produces 30 units per day.\n",
      "Megacorp owns 5 factories. 3 are high efficiency, 2 are low efficiency.\n",
      "Tomorrow they reconfigure a low efficiency factory up to medium efficiency.\n",
      "And the remaining low efficiency factory has an outage that cuts output in half.\n",
      "How many units can they produce today? How many tomorrow?\n",
      "A:\n",
      "\n",
      "\u001b[1mThe response:\u001b[0m\u001b[0m\n",
      "Today, the 3 high efficiency factories produce 3 * 100 = 300 units.\n",
      "The 2 low efficiency factories produce 2 * 30 = 60 units.\n",
      "Today, Megacorp can produce 300 + 60 = 360 units.\n",
      "Tomorrow, the reconfigured low efficiency factory will produce 60 units.\n",
      "The remaining low efficiency factory will produce 30 / 2 = 15 units.\n",
      "The 3 high efficiency factories will still produce 300 units.\n",
      "Tomorrow, Megacorp can produce 60 + 15 + 300 = 375 units.\n"
     ]
    }
   ],
   "source": [
    "better_one_shot_exemplar = \"\"\"Q: A large tennis ball can has 5 balls.\n",
    "A small tennis ball can has 3 balls.\n",
    "Roger has 3 large cans and 2 small cans today.\n",
    "Tomorrow he wins a bet and turns one small can into a large can.\n",
    "How many balls does he have today? How many tomorrow?\n",
    "A: 3 large cans is 3 * 5 = 15 tennis balls.\n",
    "2 small cans is 2 * 3 = 6 tennis balls.\n",
    "Today Roger has 15 + 6 = 21 tennis balls.\n",
    "Tomorrow's trade means losing one small tennis ball can and gaining a large can.\n",
    "Roger still has the cans he had yesterday.\n",
    "2 small cans from yesterday - 1 = 1 small can\n",
    "3 large cans from yesterday + 1 = 4 large cans\n",
    "4 large cans is 4 * 5 = 20 tennis balls.\n",
    "1 small can is 1 * 3 tennis balls.\n",
    "Tomorrow Roger has 20 + 3 = 23 tennis balls.\n",
    "Q: \"\"\"\n",
    "\n",
    "llm_call = f\"{better_one_shot_exemplar}{question}\\nA:\"\n",
    "_ = call_llm(model, parameters, llm_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRwGi1BUX8IE",
    "tags": []
   },
   "source": [
    "## Example: Table Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 954
    },
    "id": "vFFmFWgIw_Lt",
    "outputId": "cb69607c-8aa8-4ef6-e12e-63c9970b3d0d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe call to the LLM:\u001b[0m\u001b[0m\n",
      "Answer questions about a table.\n",
      "All questions must be supported by facts in the table.\n",
      "All reasoning must be done step by step.\n",
      "Explain the reasoning.\n",
      "When looking at multiple rows, explain the reasoning for each row one by one.\n",
      "\n",
      "\n",
      "| Book Name | Edition | ISBN | Publisher | Aug 1 Amazon Avg New Price | Aug 1 Amazon Avg Used Price | Aug 1 Abebooks Avg New Price | Aug 1 Abebooks Avg Used Price | Sep 1 Amazon Avg New Price | Sep 1 Amazon Avg Used Price | Sep 1 Abebooks Avg New Price | Sep 1 Abebooks Avg Used Price |\n",
      "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
      "| Physics for Computer Scientists | 10th | 978-1-118-56906-1 | Pearson Education | $149.99 | $79.99 | $142.94 | $66.94 | $129.99 | $59.99 | $139.94 | $56.94 |\n",
      "| Fundamentals of Calculus | 8th | 978-0-470-45831-0 | John Wiley & Sons | $139.99 | $99.99 | $137.94 | $87.94 | $129.99 | $79.99 | $129.94 | $76.94 |\n",
      "| Post-War British Literature | 2nd | 978-0-300-08897-2 | Oxford University Press | $129.99 | $89.99 | $122.94 | $74.94 | $119.99 | $74.99 | $124.94 | $71.94 |\n",
      "| Modern Religions: An Overview | 3rd | 978-0-19-992545-3 | Oxford University Press | $119.99 | $79.99 | $117.94 | $72.94 | $114.99 | $69.99 | $114.94 | $66.94 |\n",
      "| The Norton Introduction to Literature | 11th | 978-0-393-45078-1 | W. W. Norton & Company | $129.99 | $89.99 | $122.94 | $74.94 | $119.99 | $74.99 | $124.94 | $71.94 |\n",
      "| The Norton Anthology of American Literature | 9th | 978-0-393-93750-8 | W. W. Norton & Company | $179.99 | $139.99 | $174.94 | $127.94 | $169.99 | $124.99 | $174.94 | $121.94 |\n",
      "| The Norton Anthology of World Literature | 8th | 978-0-393-92855-6 | W. W. Norton & Company | $179.99 | $139.99 | $174.94 | $127.94 | $169.99 | $124.99 | $174.94 | $121.94 |\n",
      "| The Elements of Style | 5th | 978-0-205-11265-3 | Longman | $119.99 | $79.99 | $117.94 | $72.94 | $114.99 | $69.99 | $114.94 | $66.94 |\n",
      "\n",
      "What Oxford book dropped the most in used book price on Amazon between Aug and Sep?\n",
      "\n",
      "Answer:\n",
      "\n",
      "\u001b[1mThe response:\u001b[0m\u001b[0m\n",
      "The book Modern Religions: An Overview dropped the most in used book price on Amazon between Aug and Sep.\n",
      "\n",
      "The book Modern Religions: An Overview has an Amazon Avg Used Price of $79.99 on Aug 1 and $69.99 on Sep 1. The difference is $10.\n",
      "\n",
      "The book Post-War British Literature has an Amazon Avg Used Price of $89.99 on Aug 1 and $74.99 on Sep 1. The difference is $5.\n",
      "\n",
      "The book The Norton Introduction to Literature has an Amazon Avg Used Price of $89.99 on Aug 1 and $74.99 on Sep 1. The difference is $5.\n",
      "\n",
      "The book The Norton Anthology of American Literature has an Amazon Avg Used Price of $139.99 on Aug 1 and $124.99 on Sep 1. The difference is $15.\n",
      "\n",
      "The book The Norton Anthology of World Literature has an Amazon Avg Used Price of $139.99 on Aug 1 and $124.99 on Sep 1. The difference is $15.\n",
      "\n",
      "The book The Elements of Style has an Amazon Avg Used Price of $79.99 on Aug 1 and $69.99 on Sep 1. The difference is $10.\n",
      "\n",
      "The book Modern Religions: An Overview dropped the most in used book price on Amazon between Aug and Sep.\n"
     ]
    }
   ],
   "source": [
    "# The correct answer is Post-War British Literature.\n",
    "question = \"\"\"\n",
    "| Book Name | Edition | ISBN | Publisher | Aug 1 Amazon Avg New Price | Aug 1 Amazon Avg Used Price | Aug 1 Abebooks Avg New Price | Aug 1 Abebooks Avg Used Price | Sep 1 Amazon Avg New Price | Sep 1 Amazon Avg Used Price | Sep 1 Abebooks Avg New Price | Sep 1 Abebooks Avg Used Price |\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "| Physics for Computer Scientists | 10th | 978-1-118-56906-1 | Pearson Education | $149.99 | $79.99 | $142.94 | $66.94 | $129.99 | $59.99 | $139.94 | $56.94 |\n",
    "| Fundamentals of Calculus | 8th | 978-0-470-45831-0 | John Wiley & Sons | $139.99 | $99.99 | $137.94 | $87.94 | $129.99 | $79.99 | $129.94 | $76.94 |\n",
    "| Post-War British Literature | 2nd | 978-0-300-08897-2 | Oxford University Press | $129.99 | $89.99 | $122.94 | $74.94 | $119.99 | $74.99 | $124.94 | $71.94 |\n",
    "| Modern Religions: An Overview | 3rd | 978-0-19-992545-3 | Oxford University Press | $119.99 | $79.99 | $117.94 | $72.94 | $114.99 | $69.99 | $114.94 | $66.94 |\n",
    "| The Norton Introduction to Literature | 11th | 978-0-393-45078-1 | W. W. Norton & Company | $129.99 | $89.99 | $122.94 | $74.94 | $119.99 | $74.99 | $124.94 | $71.94 |\n",
    "| The Norton Anthology of American Literature | 9th | 978-0-393-93750-8 | W. W. Norton & Company | $179.99 | $139.99 | $174.94 | $127.94 | $169.99 | $124.99 | $174.94 | $121.94 |\n",
    "| The Norton Anthology of World Literature | 8th | 978-0-393-92855-6 | W. W. Norton & Company | $179.99 | $139.99 | $174.94 | $127.94 | $169.99 | $124.99 | $174.94 | $121.94 |\n",
    "| The Elements of Style | 5th | 978-0-205-11265-3 | Longman | $119.99 | $79.99 | $117.94 | $72.94 | $114.99 | $69.99 | $114.94 | $66.94 |\n",
    "\n",
    "What Oxford book dropped the most in used book price on Amazon between Aug and Sep?\n",
    "\"\"\"\n",
    "\n",
    "context = \"\"\"Answer questions about a table.\n",
    "All questions must be supported by facts in the table.\n",
    "All reasoning must be done step by step.\n",
    "Explain the reasoning.\n",
    "When looking at multiple rows, explain the reasoning for each row one by one.\n",
    "\"\"\"\n",
    "\n",
    "llm_call = f\"{context}\\n{question}\\nAnswer:\"\n",
    "_ = call_llm(model, parameters, llm_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_bpOTJcXviZ"
   },
   "source": [
    "Now we **add a few exemplars**.\n",
    "\n",
    "Note that the **exemplars use a different source table than the question, but the chain-of-thought reasoning still works**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SGUOqCKO_SIW",
    "outputId": "7da90243-6768-4891-fd6c-a97ff35e565d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe call to the LLM:\u001b[0m\u001b[0m\n",
      "Answer questions about a table.\n",
      "All questions must be supported by facts in the table.\n",
      "All reasoning must be done step by step.\n",
      "Explain the reasoning.\n",
      "When looking at multiple rows, explain the reasoning for each row one by one.\n",
      "\n",
      "\n",
      "Table:\n",
      "| Item Name | SKU | Vendor | Aug 1 Inventory | Sep 1 Inventory | Sale Count |\n",
      "|---|---|---|---|---|---|\n",
      "| iPhone 13 Pro Max | MGL83LL/A | Apple | 100 | 80 | 17 |\n",
      "| iPhone 13 Pro | MLL03LL/A | Apple | 50 | 40 | 9 |\n",
      "| iPhone 13 | MLKG3LL/A | Apple | 25 | 20 | 4 |\n",
      "| Samsung Galaxy S22 Ultra | SM-S908U | Samsung | 100 | 80 | 19 |\n",
      "| Samsung Galaxy S22 Plus | SM-S906U | Samsung | 50 | 40 | 10 |\n",
      "| Samsung Galaxy S22 | SM-S901U | Samsung | 25 | 20 | 5 |\n",
      "| Google Pixel 6 Pro | GA01314-US | Google | 100 | 80 | 20 |\n",
      "\n",
      "Question:\n",
      "What iPhone sold the most in August?\n",
      "Answer: I need to look at each item one by one and determine if it is an iPhone.\n",
      "Only iPhone items are considered.\n",
      "The iPhone items are the iPhone 13 Pro Max, the iPhone 13 Pro, and the iPhone 13.\n",
      "I need to look at how much each iPhone sold one by one, and then see which sold count is the highest.\n",
      "iPhone 13 Pro Max sale count is 17.\n",
      "iPhone 13 Pro sale count is 9.\n",
      "iPhone 13 sale count is 4.\n",
      "The biggest number of 17, 9, and 4 is 17.\n",
      "The answer is iPhone 13 Pro Max.\n",
      "\n",
      "Table:\n",
      "| Item Name | SKU | Vendor | Aug 1 Inventory | Sep 1 Inventory | Sale Count |\n",
      "|---|---|---|---|---|---|\n",
      "| iPhone 13 Pro Max | MGL83LL/A | Apple | 100 | 80 | 17 |\n",
      "| iPhone 13 Pro | MLL03LL/A | Apple | 50 | 40 | 9 |\n",
      "| iPhone 13 | MLKG3LL/A | Apple | 25 | 20 | 4 |\n",
      "| Samsung Galaxy S22 Ultra | SM-S908U | Samsung | 100 | 80 | 19 |\n",
      "| Samsung Galaxy S22 Plus | SM-S906U | Samsung | 50 | 40 | 10 |\n",
      "| Samsung Galaxy S22 | SM-S901U | Samsung | 25 | 20 | 5 |\n",
      "| Google Pixel 6 Pro | GA01314-US | Google | 100 | 80 | 20 |\n",
      "\n",
      "Question:\n",
      "What Samsung phone has the most units unaccounted for on Sep 1?\n",
      "Answer: I need to look at each item one by one and determine if it is a Samsung item.\n",
      "I have to look at the Item Name for Samsung items.\n",
      "Only Samsung items are considered.\n",
      "The Samsung items are the S22 Ultra, the S22 Plus, and the S22.\n",
      "One by one, I need to look at the Sep 1 and Aug 1 inventory difference for each Samsung item to see how many units should have been sold.\n",
      "Then I need to compare that number to the actual sale count value for that item.\n",
      "The phone with the biggest difference between the sale count field and the inventory differences is the most unaccounted for.\n",
      "Samsung Galaxy S22 Ultra had 100 in stock Aug 1 and 80 in stock Sep 1. 100 minus 80 is 20 (100 - 80 = 20). Sale count is 19. 20 minus 19 is 1 (20 - 19 = 1). 1 unit is unaccounted for.\n",
      "Samsung Galaxy S22 Plus had 50 in stock Aug 1 and 40 in stock Sep 1. 50 minus 40 is 10 (50 - 40 = 10). Sale count is 10. The sale count matches the inventory difference, no units are unaccounted for.\n",
      "Samsung Galaxy S22 had 25 in stock Aug 1 and 20 in stock Sep 1. 25 minus 20 is 5 (25 - 20 = 5). Sale count is 5. 20 minus 19 is 1. The sale count matches the inventory difference, no units are unaccounted for.\n",
      "Only the S22 Ultra had anything unaccounted for.\n",
      "The answer is Samsung Galaxy S22 Ultra.\n",
      "\n",
      "Table:\n",
      "| Item Name | SKU | Vendor | Aug 1 Inventory | Sep 1 Inventory | Sale Count |\n",
      "|---|---|---|---|---|---|\n",
      "| iPhone 13 Pro Max | MGL83LL/A | Apple | 100 | 80 | 17 |\n",
      "| iPhone 13 Pro | MLL03LL/A | Apple | 50 | 40 | 9 |\n",
      "| iPhone 13 | MLKG3LL/A | Apple | 25 | 20 | 4 |\n",
      "| Samsung Galaxy S22 Ultra | SM-S908U | Samsung | 100 | 80 | 19 |\n",
      "| Samsung Galaxy S22 Plus | SM-S906U | Samsung | 50 | 40 | 10 |\n",
      "| Samsung Galaxy S22 | SM-S901U | Samsung | 25 | 20 | 5 |\n",
      "| Google Pixel 6 Pro | GA01314-US | Google | 100 | 80 | 20 |\n",
      "\n",
      "Question:\n",
      "What vendor had the most total sales?\n",
      "Answer: I need to look at the vendors one by one.\n",
      "I have to deduce the vendors from the Item Name field.\n",
      "There are three unique vendors in the table: Apple, Samsung, and Google.\n",
      "For each vendor, I need to find the sale count for each item one by one, then add up the sales counts.\n",
      "The Apple items are the iPhone 13 Pro Max with 17 sales, the iPhone 13 Pro with 9 sales, and the iPhone 13 with 4 sales.\n",
      "17 + 9 + 4 = 30. 30 Apple phones were sold.\n",
      "The Samsung items are the Samsung Galaxy S22 Ultra with 19 sales, the Samsung Galaxy S22 Plus with 10 sales, and the Samsung Galaxy S22 with 5 sales.\n",
      "19 + 10 + 5 = 34. 34 Samsung phones were sold.\n",
      "The Google item is the Google Pixel 6 Pro with 20 sales. 20 Google phones were sold.\n",
      "30 Apple, 34 Samsung, 20 Google. 34 is the biggest number, it is for Samsung sales.\n",
      "The answer is Samsung.\n",
      "\n",
      "Table:\n",
      "| Item Name | SKU | Vendor | Aug 1 Inventory | Sep 1 Inventory | Sale Count |\n",
      "|---|---|---|---|---|---|\n",
      "| iPhone 13 Pro Max | MGL83LL/A | Apple | 100 | 80 | 17 |\n",
      "| iPhone 13 Pro | MLL03LL/A | Apple | 50 | 40 | 9 |\n",
      "| iPhone 13 | MLKG3LL/A | Apple | 25 | 20 | 4 |\n",
      "| Samsung Galaxy S22 Ultra | SM-S908U | Samsung | 100 | 80 | 19 |\n",
      "| Samsung Galaxy S22 Plus | SM-S906U | Samsung | 50 | 40 | 10 |\n",
      "| Samsung Galaxy S22 | SM-S901U | Samsung | 25 | 20 | 5 |\n",
      "| Google Pixel 6 Pro | GA01314-US | Google | 100 | 80 | 20 |\n",
      "\n",
      "Question:\n",
      "What item had the most sales?\n",
      "Answer: I need to look at each item one by one.\n",
      "The iPhone 13 Pro Max had 17 sales.\n",
      "The iPhone 13 Pro had 9 sales.\n",
      "The iPhone 13 had 4 sales.\n",
      "The Samsung Galaxy S22 Ultra had 19 sales.\n",
      "The Samsung Galaxy S22 Plus had 10 sales.\n",
      "The Samsung Galaxy S22 had 5 sales.\n",
      "The Google Pixel 6 Pro had 20 sales.\n",
      "The sales numbers are 17, 9, 3, 19, 10, 5, and 20.\n",
      "20 is the biggest sales number, that is for the Google Pixel 6 Pro.\n",
      "The answer is the Google Pixel 6 Pro.\n",
      "\n",
      "\n",
      "| Book Name | Edition | ISBN | Publisher | Aug 1 Amazon Avg New Price | Aug 1 Amazon Avg Used Price | Aug 1 Abebooks Avg New Price | Aug 1 Abebooks Avg Used Price | Sep 1 Amazon Avg New Price | Sep 1 Amazon Avg Used Price | Sep 1 Abebooks Avg New Price | Sep 1 Abebooks Avg Used Price |\n",
      "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
      "| Physics for Computer Scientists | 10th | 978-1-118-56906-1 | Pearson Education | $149.99 | $79.99 | $142.94 | $66.94 | $129.99 | $59.99 | $139.94 | $56.94 |\n",
      "| Fundamentals of Calculus | 8th | 978-0-470-45831-0 | John Wiley & Sons | $139.99 | $99.99 | $137.94 | $87.94 | $129.99 | $79.99 | $129.94 | $76.94 |\n",
      "| Post-War British Literature | 2nd | 978-0-300-08897-2 | Oxford University Press | $129.99 | $89.99 | $122.94 | $74.94 | $119.99 | $74.99 | $124.94 | $71.94 |\n",
      "| Modern Religions: An Overview | 3rd | 978-0-19-992545-3 | Oxford University Press | $119.99 | $79.99 | $117.94 | $72.94 | $114.99 | $69.99 | $114.94 | $66.94 |\n",
      "| The Norton Introduction to Literature | 11th | 978-0-393-45078-1 | W. W. Norton & Company | $129.99 | $89.99 | $122.94 | $74.94 | $119.99 | $74.99 | $124.94 | $71.94 |\n",
      "| The Norton Anthology of American Literature | 9th | 978-0-393-93750-8 | W. W. Norton & Company | $179.99 | $139.99 | $174.94 | $127.94 | $169.99 | $124.99 | $174.94 | $121.94 |\n",
      "| The Norton Anthology of World Literature | 8th | 978-0-393-92855-6 | W. W. Norton & Company | $179.99 | $139.99 | $174.94 | $127.94 | $169.99 | $124.99 | $174.94 | $121.94 |\n",
      "| The Elements of Style | 5th | 978-0-205-11265-3 | Longman | $119.99 | $79.99 | $117.94 | $72.94 | $114.99 | $69.99 | $114.94 | $66.94 |\n",
      "\n",
      "What Oxford book dropped the most in used book price on Amazon between Aug and Sep?\n",
      "\n",
      "Answer:\n",
      "\n",
      "\u001b[1mThe response:\u001b[0m\u001b[0m\n",
      "I need to look at the books published by Oxford University Press.\n",
      "There are 3 books published by Oxford University Press: Post-War British Literature, Modern Religions: An Overview, and The Elements of Style.\n",
      "I need to look at the used book price on Amazon for each book between Aug and Sep.\n",
      "Post-War British Literature: Aug 1 Amazon Avg Used Price is $89.99, Sep 1 Amazon Avg Used Price is $74.99. The price dropped by $15.\n",
      "Modern Religions: An Overview: Aug 1 Amazon Avg Used Price is $79.99, Sep 1 Amazon Avg Used Price is $69.99. The price dropped by $10.\n",
      "The Elements of Style: Aug 1 Amazon Avg Used Price is $79.99, Sep 1 Amazon Avg Used Price is $69.99. The price dropped by $10.\n",
      "The price dropped by $15 for Post-War British Literature, $10 for Modern Religions: An Overview, and $10 for The Elements of Style.\n",
      "The price dropped the most for Post-War British Literature.\n",
      "The answer is Post-War British Literature.\n"
     ]
    }
   ],
   "source": [
    "few_shot_exemplar = \"\"\"\n",
    "Table:\n",
    "| Item Name | SKU | Vendor | Aug 1 Inventory | Sep 1 Inventory | Sale Count |\n",
    "|---|---|---|---|---|---|\n",
    "| iPhone 13 Pro Max | MGL83LL/A | Apple | 100 | 80 | 17 |\n",
    "| iPhone 13 Pro | MLL03LL/A | Apple | 50 | 40 | 9 |\n",
    "| iPhone 13 | MLKG3LL/A | Apple | 25 | 20 | 4 |\n",
    "| Samsung Galaxy S22 Ultra | SM-S908U | Samsung | 100 | 80 | 19 |\n",
    "| Samsung Galaxy S22 Plus | SM-S906U | Samsung | 50 | 40 | 10 |\n",
    "| Samsung Galaxy S22 | SM-S901U | Samsung | 25 | 20 | 5 |\n",
    "| Google Pixel 6 Pro | GA01314-US | Google | 100 | 80 | 20 |\n",
    "\n",
    "Question:\n",
    "What iPhone sold the most in August?\n",
    "Answer: I need to look at each item one by one and determine if it is an iPhone.\n",
    "Only iPhone items are considered.\n",
    "The iPhone items are the iPhone 13 Pro Max, the iPhone 13 Pro, and the iPhone 13.\n",
    "I need to look at how much each iPhone sold one by one, and then see which sold count is the highest.\n",
    "iPhone 13 Pro Max sale count is 17.\n",
    "iPhone 13 Pro sale count is 9.\n",
    "iPhone 13 sale count is 4.\n",
    "The biggest number of 17, 9, and 4 is 17.\n",
    "The answer is iPhone 13 Pro Max.\n",
    "\n",
    "Table:\n",
    "| Item Name | SKU | Vendor | Aug 1 Inventory | Sep 1 Inventory | Sale Count |\n",
    "|---|---|---|---|---|---|\n",
    "| iPhone 13 Pro Max | MGL83LL/A | Apple | 100 | 80 | 17 |\n",
    "| iPhone 13 Pro | MLL03LL/A | Apple | 50 | 40 | 9 |\n",
    "| iPhone 13 | MLKG3LL/A | Apple | 25 | 20 | 4 |\n",
    "| Samsung Galaxy S22 Ultra | SM-S908U | Samsung | 100 | 80 | 19 |\n",
    "| Samsung Galaxy S22 Plus | SM-S906U | Samsung | 50 | 40 | 10 |\n",
    "| Samsung Galaxy S22 | SM-S901U | Samsung | 25 | 20 | 5 |\n",
    "| Google Pixel 6 Pro | GA01314-US | Google | 100 | 80 | 20 |\n",
    "\n",
    "Question:\n",
    "What Samsung phone has the most units unaccounted for on Sep 1?\n",
    "Answer: I need to look at each item one by one and determine if it is a Samsung item.\n",
    "I have to look at the Item Name for Samsung items.\n",
    "Only Samsung items are considered.\n",
    "The Samsung items are the S22 Ultra, the S22 Plus, and the S22.\n",
    "One by one, I need to look at the Sep 1 and Aug 1 inventory difference for each Samsung item to see how many units should have been sold.\n",
    "Then I need to compare that number to the actual sale count value for that item.\n",
    "The phone with the biggest difference between the sale count field and the inventory differences is the most unaccounted for.\n",
    "Samsung Galaxy S22 Ultra had 100 in stock Aug 1 and 80 in stock Sep 1. 100 minus 80 is 20 (100 - 80 = 20). Sale count is 19. 20 minus 19 is 1 (20 - 19 = 1). 1 unit is unaccounted for.\n",
    "Samsung Galaxy S22 Plus had 50 in stock Aug 1 and 40 in stock Sep 1. 50 minus 40 is 10 (50 - 40 = 10). Sale count is 10. The sale count matches the inventory difference, no units are unaccounted for.\n",
    "Samsung Galaxy S22 had 25 in stock Aug 1 and 20 in stock Sep 1. 25 minus 20 is 5 (25 - 20 = 5). Sale count is 5. 20 minus 19 is 1. The sale count matches the inventory difference, no units are unaccounted for.\n",
    "Only the S22 Ultra had anything unaccounted for.\n",
    "The answer is Samsung Galaxy S22 Ultra.\n",
    "\n",
    "Table:\n",
    "| Item Name | SKU | Vendor | Aug 1 Inventory | Sep 1 Inventory | Sale Count |\n",
    "|---|---|---|---|---|---|\n",
    "| iPhone 13 Pro Max | MGL83LL/A | Apple | 100 | 80 | 17 |\n",
    "| iPhone 13 Pro | MLL03LL/A | Apple | 50 | 40 | 9 |\n",
    "| iPhone 13 | MLKG3LL/A | Apple | 25 | 20 | 4 |\n",
    "| Samsung Galaxy S22 Ultra | SM-S908U | Samsung | 100 | 80 | 19 |\n",
    "| Samsung Galaxy S22 Plus | SM-S906U | Samsung | 50 | 40 | 10 |\n",
    "| Samsung Galaxy S22 | SM-S901U | Samsung | 25 | 20 | 5 |\n",
    "| Google Pixel 6 Pro | GA01314-US | Google | 100 | 80 | 20 |\n",
    "\n",
    "Question:\n",
    "What vendor had the most total sales?\n",
    "Answer: I need to look at the vendors one by one.\n",
    "I have to deduce the vendors from the Item Name field.\n",
    "There are three unique vendors in the table: Apple, Samsung, and Google.\n",
    "For each vendor, I need to find the sale count for each item one by one, then add up the sales counts.\n",
    "The Apple items are the iPhone 13 Pro Max with 17 sales, the iPhone 13 Pro with 9 sales, and the iPhone 13 with 4 sales.\n",
    "17 + 9 + 4 = 30. 30 Apple phones were sold.\n",
    "The Samsung items are the Samsung Galaxy S22 Ultra with 19 sales, the Samsung Galaxy S22 Plus with 10 sales, and the Samsung Galaxy S22 with 5 sales.\n",
    "19 + 10 + 5 = 34. 34 Samsung phones were sold.\n",
    "The Google item is the Google Pixel 6 Pro with 20 sales. 20 Google phones were sold.\n",
    "30 Apple, 34 Samsung, 20 Google. 34 is the biggest number, it is for Samsung sales.\n",
    "The answer is Samsung.\n",
    "\n",
    "Table:\n",
    "| Item Name | SKU | Vendor | Aug 1 Inventory | Sep 1 Inventory | Sale Count |\n",
    "|---|---|---|---|---|---|\n",
    "| iPhone 13 Pro Max | MGL83LL/A | Apple | 100 | 80 | 17 |\n",
    "| iPhone 13 Pro | MLL03LL/A | Apple | 50 | 40 | 9 |\n",
    "| iPhone 13 | MLKG3LL/A | Apple | 25 | 20 | 4 |\n",
    "| Samsung Galaxy S22 Ultra | SM-S908U | Samsung | 100 | 80 | 19 |\n",
    "| Samsung Galaxy S22 Plus | SM-S906U | Samsung | 50 | 40 | 10 |\n",
    "| Samsung Galaxy S22 | SM-S901U | Samsung | 25 | 20 | 5 |\n",
    "| Google Pixel 6 Pro | GA01314-US | Google | 100 | 80 | 20 |\n",
    "\n",
    "Question:\n",
    "What item had the most sales?\n",
    "Answer: I need to look at each item one by one.\n",
    "The iPhone 13 Pro Max had 17 sales.\n",
    "The iPhone 13 Pro had 9 sales.\n",
    "The iPhone 13 had 4 sales.\n",
    "The Samsung Galaxy S22 Ultra had 19 sales.\n",
    "The Samsung Galaxy S22 Plus had 10 sales.\n",
    "The Samsung Galaxy S22 had 5 sales.\n",
    "The Google Pixel 6 Pro had 20 sales.\n",
    "The sales numbers are 17, 9, 3, 19, 10, 5, and 20.\n",
    "20 is the biggest sales number, that is for the Google Pixel 6 Pro.\n",
    "The answer is the Google Pixel 6 Pro.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Prepending the few shot exemplars before the question we want answered.\n",
    "llm_call = f\"{context}\\n{few_shot_exemplar}{question}\\nAnswer:\"\n",
    "_ = call_llm(model, parameters, llm_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vf0vyGCAZndK"
   },
   "source": [
    "Two more questions (suppressing the model call for readability):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "id": "Dm_GnH8yZb9-",
    "outputId": "9dbed298-b391-46e7-e959-5fbff4cff122"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need to find the price of 3 new copies of The Elements of Style from Amazon and Abebooks in August.\n",
      "The price of 1 new copy of The Elements of Style from Amazon is $119.99.\n",
      "The price of 3 new copies of The Elements of Style from Amazon is $119.99 * 3 = $359.97.\n",
      "The price of 1 new copy of The Elements of Style from Abebooks is $117.94.\n",
      "The price of 3 new copies of The Elements of Style from Abebooks is $117.94 * 3 = $353.82.\n",
      "The difference in price is $359.97 - $353.82 = $6.15.\n",
      "The answer is $6.15.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The correct answer is $6.15.\n",
    "question = \"\"\"\n",
    "Table:\n",
    "| Book Name | Edition | ISBN | Publisher | Aug 1 Amazon Avg New Price | Aug 1 Amazon Avg Used Price | Aug 1 Abebooks Avg New Price | Aug 1 Abebooks Avg Used Price | Sep 1 Amazon Avg New Price | Sep 1 Amazon Avg Used Price | Sep 1 Abebooks Avg New Price | Sep 1 Abebooks Avg Used Price |\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "| Physics for Computer Scientists | 10th | 978-1-118-56906-1 | Pearson Education | $149.99 | $79.99 | $142.94 | $66.94 | $129.99 | $59.99 | $139.94 | $56.94 |\n",
    "| Fundamentals of Calculus | 8th | 978-0-470-45831-0 | John Wiley & Sons | $139.99 | $99.99 | $137.94 | $87.94 | $129.99 | $79.99 | $129.94 | $76.94 |\n",
    "| Post-War British Literature | 2nd | 978-0-300-08897-2 | Oxford University Press | $129.99 | $89.99 | $122.94 | $74.94 | $119.99 | $74.99 | $124.94 | $71.94 |\n",
    "| Modern Religions: An Overview | 3rd | 978-0-19-992545-3 | Oxford University Press | $119.99 | $79.99 | $117.94 | $72.94 | $114.99 | $69.99 | $114.94 | $66.94 |\n",
    "| The Norton Introduction to Literature | 11th | 978-0-393-45078-1 | W. W. Norton & Company | $129.99 | $89.99 | $122.94 | $74.94 | $119.99 | $74.99 | $124.94 | $71.94 |\n",
    "| The Norton Anthology of World Literature | 8th | 978-0-393-92855-6 | W. W. Norton & Company | $179.99 | $139.99 | $174.94 | $127.94 | $169.99 | $124.99 | $174.94 | $121.94 |\n",
    "| The Elements of Style | 5th | 978-0-205-11265-3 | Longman | $119.99 | $79.99 | $117.94 | $72.94 | $114.99 | $69.99 | $114.94 | $66.94 |\n",
    "\n",
    "Question:\n",
    "How much money would be saved if I purchased 3 new copies of the Elements of Style from Abe books instead of Amazon in August?\n",
    "\"\"\"\n",
    "\n",
    "llm_call = f\"{context}\\n{few_shot_exemplar}{question}\\nAnswer:\"\n",
    "print(call_llm(model, parameters, llm_call, show_activity=False))\n",
    "\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need to look at the Aug 1 Amazon Avg New Price and the Aug 1 Amazon Avg Used Price for each book.\n",
      "The difference between the new and used prices is the new price minus the used price.\n",
      "The book with the largest difference is the one with the biggest difference between the new and used prices.\n",
      "The book with the largest difference is Physics for Computer Scientists.\n",
      "The new price is $149.99 and the used price is $79.99.\n",
      "The difference is $149.99 - $79.99 = $70.00.\n",
      "The answer is Physics for Computer Scientists.\n"
     ]
    }
   ],
   "source": [
    "# The correct answer is Physics for Computer Scientists.\n",
    "question = \"\"\"\n",
    "Table:\n",
    "| Book Name | Edition | ISBN | Publisher | Aug 1 Amazon Avg New Price | Aug 1 Amazon Avg Used Price | Aug 1 Abebooks Avg New Price | Aug 1 Abebooks Avg Used Price | Sep 1 Amazon Avg New Price | Sep 1 Amazon Avg Used Price | Sep 1 Abebooks Avg New Price | Sep 1 Abebooks Avg Used Price |\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "| Physics for Computer Scientists | 10th | 978-1-118-56906-1 | Pearson Education | $149.99 | $79.99 | $142.94 | $66.94 | $129.99 | $59.99 | $139.94 | $56.94 |\n",
    "| Fundamentals of Calculus | 8th | 978-0-470-45831-0 | John Wiley & Sons | $139.99 | $99.99 | $137.94 | $87.94 | $129.99 | $79.99 | $129.94 | $76.94 |\n",
    "| Post-War British Literature | 2nd | 978-0-300-08897-2 | Oxford University Press | $129.99 | $89.99 | $122.94 | $74.94 | $119.99 | $74.99 | $124.94 | $71.94 |\n",
    "| Modern Religions: An Overview | 3rd | 978-0-19-992545-3 | Oxford University Press | $119.99 | $79.99 | $117.94 | $72.94 | $114.99 | $69.99 | $114.94 | $66.94 |\n",
    "| The Norton Introduction to Literature | 11th | 978-0-393-45078-1 | W. W. Norton & Company | $129.99 | $89.99 | $122.94 | $74.94 | $119.99 | $74.99 | $124.94 | $71.94 |\n",
    "| The Norton Anthology of World Literature | 8th | 978-0-393-92855-6 | W. W. Norton & Company | $179.99 | $139.99 | $174.94 | $127.94 | $169.99 | $124.99 | $174.94 | $121.94 |\n",
    "| The Elements of Style | 5th | 978-0-205-11265-3 | Longman | $119.99 | $79.99 | $117.94 | $72.94 | $114.99 | $69.99 | $114.94 | $66.94 |\n",
    "\n",
    "Question: What book has the largest difference between new and used Aug Amazon prices?\n",
    "\"\"\"\n",
    "\n",
    "llm_call = f\"{context}\\n{few_shot_exemplar}{question}\\nAnswer:\"\n",
    "print(call_llm(model, parameters, llm_call, show_activity=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jk98xwBpSnl"
   },
   "source": [
    "For a data understanding use case, if you know the data schema ahead of time your exemplars should match that schema.\n",
    "\n",
    "Generally, the more alike in structure the exemplar data structures are to the question data structure, the more likely the LLM responds correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWB4WcfdaLNi",
    "tags": []
   },
   "source": [
    "## Example: Tagging Data and Structured Data Output\n",
    "\n",
    "This example does both. Tagging performance improves with chain-of-thought exemplars that reason through why certain tags are best (and provide interpretability for why the tags were chosen).\n",
    "\n",
    "Additionally, showing what the structured data output should look like, even for a common data format like JSON, will improve performance.\n",
    "\n",
    "[Data source](https://data.amerigeoss.org/dataset/gsa-json-adc1d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "id": "9xOLcvQdXWfd",
    "outputId": "ed0f90a9-3d95-424d-df5f-0769f62c370a"
   },
   "outputs": [],
   "source": [
    "context = \"\"\"Given a JSON entry of a data source, output a JSON with the following fields and explain the reasoning:\n",
    "pii: True/False, the dataset contains Personally Identifiable Information.\n",
    "age: How many years since the dataset was last modified.\n",
    "keywords: New keywords to index this dataset under, beyond the current set of keywords.\n",
    "The last text output should be the JSON.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "question = \"\"\"\n",
    "{\n",
    "    \"@type\" : \"dcat:Dataset\",\n",
    "    \"description\" : \"<p>The MDS 3.0 Frequency Report summarizes information for active residents currently in nursing homes. The source of these counts is the residents MDS assessment record. The MDS assessment information for each active nursing home resident is consolidated to create a profile of the most recent standard information for the resident.</p>\\n\",\n",
    "    \"title\" : \"MDS 3.0 Frequency Report\",\n",
    "    \"accessLevel\" : \"public\",\n",
    "    \"identifier\" : \"465\",\n",
    "    \"license\" : \"http://opendefinition.org/licenses/odc-odbl/\",\n",
    "    \"modified\" : \"2016-04-05\",\n",
    "    \"temporal\" : \"2012-01-01T00:00:00-05:00/2015-12-31T00:00:00-05:00\",\n",
    "    \"contactPoint\" : {\n",
    "      \"@type\" : \"vcard:Contact\",\n",
    "      \"fn\" : \"Health Data Initiative\",\n",
    "      \"hasEmail\" : \"mailto:HealthData@hhs.gov\"\n",
    "    },\n",
    "    \"bureauCode\" : [ \"009:38\" ],\n",
    "    \"keyword\" : [ \"Activities of Daily Living (ADL)\" ],\n",
    "    \"language\" : [ \"en\" ],\n",
    "    \"programCode\" : [ \"009:000\" ],\n",
    "    \"publisher\" : {\n",
    "      \"@type\" : \"org:Organization\",\n",
    "      \"name\" : \"Centers for Medicare & Medicaid Services\",\n",
    "      \"subOrganizationOf\" : {\n",
    "        \"@type\" : \"org:Organization\",\n",
    "        \"name\" : \"Department of Health & Human Services\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "llm_call = f\"{context}\\nJSON:{question}\\nAnswer:\"\n",
    "_ = call_llm(model, parameters, llm_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0W-zY4uewRs"
   },
   "source": [
    "The JSON format is correct, but age is wrong and no keywords were predicted. Adding one exemplar leads to a correct response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qUn2EeXQe6pu",
    "outputId": "f14170ad-651f-46f2-e1c7-af00b63f7fe1"
   },
   "outputs": [],
   "source": [
    "one_shot_exemplar = \"\"\"\n",
    "JSON:\n",
    "{\n",
    "\n",
    "    \"@type\" : \"dcat:Dataset\",\n",
    "    \"description\" : \"The primary purpose of this system of records is to properly pay medical insurance benefits to or on behalf of entitled beneficiaries.\",\n",
    "    \"title\" : \"Medicare Multi-Carrier Claims System\",\n",
    "    \"accessLevel\" : \"restricted public\",\n",
    "    \"dataQuality\" : true,\n",
    "    \"identifier\" : \"b6ffafab-1cfd-42dd-b8cb-7a554efaefa7\",\n",
    "    \"landingPage\" : \"http://www.cms.gov/Research-Statistics-Data-and-Systems/Computer-Data-and-Systems/Privacy/Systems-of-Records-Items/09-70-0501-MCS.html\",\n",
    "    \"license\" : \"http://www.usa.gov/publicdomain/label/1.0/\",\n",
    "    \"modified\" : \"2014-09-30\",\n",
    "    \"rights\" : \"Contains personally identifiable information and is subject to the Privacy Act of 1974, as amended at 5 United States Code (U.S.C.) 552a.  Requests should be directed to the appropriate System Manager, identified in the System of Records notice.\",\n",
    "    \"primaryITInvestmentUII\" : \"009-000004256, 009-000004254\",\n",
    "    \"systemOfRecords\" : \"09-70-0501\",\n",
    "\n",
    "    \"contactPoint\" : {\n",
    "      \"@type\" : \"vcard:Contact\",\n",
    "      \"fn\" : \"Health Data Initiative\",\n",
    "      \"hasEmail\" : \"mailto:Healthdata@hhs.gov\"\n",
    "    },\n",
    "    \"bureauCode\" : [ \"009:38\" ],\n",
    "    \"keyword\" : [ \"medicare\", \"part b\", \"claims\" ],\n",
    "    \"programCode\" : [ \"009:078\" ],\n",
    "    \"theme\" : [ \"Medicare\" ],\n",
    "    \"publisher\" : {\n",
    "      \"@type\" : \"org:Organization\",\n",
    "      \"name\" : \"Centers for Medicare & Medicaid Services\",\n",
    "      \"subOrganizationOf\" : {\n",
    "        \"@type\" : \"org:Organization\",\n",
    "        \"name\" : \"Department of Health & Human Services\"\n",
    "      }\n",
    "    }\n",
    "  }Âº\n",
    "\n",
    "Answer: The 'rights' tag says 'Contains personally identifiable information' so pii is True.\n",
    "The 'modified' tag is '2014-09-30'. The current year is 2023, 2023 minus 2014 is 9, so the age is 9.\n",
    "To determine keywords I will look at all the fields that describe the dataset.\n",
    "Then I will take the most salient and distinctive aspects of the fields and make those keywords.\n",
    "Looking at all the fields, the ones that describe the dataset are  \"description\" and \"title\".\n",
    "The \"title\" field is \"Medicare Multi-Carrier Claims System\".\n",
    "Good keywords from the \"title\" field are \"medicare\" and \"claims\".\n",
    "The \"description\" field is \"\"The primary purpose of this system of records is to properly pay medical insurance benefits to or on behalf of entitled beneficiaries.\"\n",
    "Good keywords from the \"description\" field are \"medical insurance benefits\".\n",
    "Good proposed keywords from both fields are \"medicare\", \"claims\", and \"medical insurance benefits\".\n",
    "Next inspect the \"keyword\" field to make sure the proposed keywords are not already included.\n",
    "The \"keyword\" field contains the keywords \"medicare\", \"part b\", and \"claims\".\n",
    "From our proposed keywords, \"medicare\" should not be output since it is already in the \"keyword\" field.\n",
    "That leaves \"claims\" and \"medical insurance benefits\" as proposed keywords.\n",
    "\n",
    "Output JSON:\n",
    "{\n",
    "  \"pii\" : true,\n",
    "  \"age\" : 9,\n",
    "  \"keywords\" : [\"claims\", \"medical insurance benefits\"]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Prepending the one shot exemplar before the question we want answered.\n",
    "llm_call = f\"{context}{one_shot_exemplar}\\nJSON:{question}\\nAnswer:\"\n",
    "_ = call_llm(model, parameters, llm_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tbtSBsrpjg56"
   },
   "source": [
    "The output is correct but the reasoning on keyword overlap could be clearer, which would make the prompt more robust. Think about to improve this, then see the next cell for one solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HIGy06bNkdNf",
    "outputId": "6827d253-c0b9-4d11-ac4d-2c514dae8717",
    "tags": []
   },
   "outputs": [],
   "source": [
    "few_shot_exemplar = \"\"\"\n",
    "JSON:\n",
    "{\n",
    "\n",
    "    \"@type\" : \"dcat:Dataset\",\n",
    "    \"description\" : \"The primary purpose of this system of records is to properly pay medical insurance benefits to or on behalf of entitled beneficiaries.\",\n",
    "    \"title\" : \"Medicare Multi-Carrier Claims System\",\n",
    "    \"accessLevel\" : \"restricted public\",\n",
    "    \"dataQuality\" : true,\n",
    "    \"identifier\" : \"b6ffafab-1cfd-42dd-b8cb-7a554efaefa7\",\n",
    "    \"landingPage\" : \"http://www.cms.gov/Research-Statistics-Data-and-Systems/Computer-Data-and-Systems/Privacy/Systems-of-Records-Items/09-70-0501-MCS.html\",\n",
    "    \"license\" : \"http://www.usa.gov/publicdomain/label/1.0/\",\n",
    "    \"modified\" : \"2014-09-30\",\n",
    "    \"rights\" : \"Contains personally identifiable information and is subject to the Privacy Act of 1974, as amended at 5 United States Code (U.S.C.) 552a.  Requests should be directed to the appropriate System Manager, identified in the System of Records notice.\",\n",
    "    \"primaryITInvestmentUII\" : \"009-000004256, 009-000004254\",\n",
    "    \"systemOfRecords\" : \"09-70-0501\",\n",
    "\n",
    "    \"contactPoint\" : {\n",
    "      \"@type\" : \"vcard:Contact\",\n",
    "      \"fn\" : \"Health Data Initiative\",\n",
    "      \"hasEmail\" : \"mailto:Healthdata@hhs.gov\"\n",
    "    },\n",
    "    \"bureauCode\" : [ \"009:38\" ],\n",
    "    \"keyword\" : [ \"medicare\", \"part b\", \"claims\" ],\n",
    "    \"programCode\" : [ \"009:078\" ],\n",
    "    \"theme\" : [ \"Medicare\" ],\n",
    "    \"publisher\" : {\n",
    "      \"@type\" : \"org:Organization\",\n",
    "      \"name\" : \"Centers for Medicare & Medicaid Services\",\n",
    "      \"subOrganizationOf\" : {\n",
    "        \"@type\" : \"org:Organization\",\n",
    "        \"name\" : \"Department of Health & Human Services\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "Answer: The \"rights\" field says 'Contains personally identifiable information' so pii is true.\n",
    "The \"modified\" field is \"2014-09-30\". The current year is 2023, 2023 minus 2014 is 9, so the age is 9.\n",
    "To determine keywords I will look at all the fields that describe the dataset.\n",
    "Then I will take the most salient and distinctive aspects of the fields and make those keywords.\n",
    "Looking at all the fields, the ones that describe the dataset are \"description\" and \"title\".\n",
    "The \"title\" field is \"Medicare Multi-Carrier Claims System\".\n",
    "Good keywords from the \"title\" field are \"medicare\" and \"claims\".\n",
    "The \"description\" field is \"The primary purpose of this system of records is to properly pay medical insurance benefits to or on behalf of entitled beneficiaries.\"\n",
    "Good keywords from the \"description\" field are \"medical insurance benefits\".\n",
    "Good proposed keywords from both fields are \"medicare\", \"claims\", and \"medical insurance benefits\".\n",
    "Next inspect the \"keyword\" field to make sure the proposed keywords are not already included.\n",
    "The \"keyword\" field contains the keywords \"medicare\", \"part b\", and \"claims\".\n",
    "From our proposed keywords, \"medicare\" should not be output since it is already in the \"keyword\" field.\n",
    "That leaves \"claims\" and \"medical insurance benefits\" as acceptable new keywords.\n",
    "\n",
    "Output JSON:\n",
    "{\n",
    "  \"pii\" : true,\n",
    "  \"age\" : 9,\n",
    "  \"keywords\" : [\"claims\", \"medical insurance benefits\"]\n",
    "}\n",
    "\n",
    "\n",
    "JSON:\n",
    "{\n",
    "  \"@type\": \"dcat:Dataset\",\n",
    "  \"title\": \"Data.gov Top 10 Visiting Countries - Archival\",\n",
    "  \"description\": \"This dataset provides top 10 visiting countries by month in Data.gov up to July 2013.\",\n",
    "  \"modified\": \"2016-01-20\",\n",
    "  \"accessLevel\": \"public\",\n",
    "  \"identifier\": \"GSA-32491\",\n",
    "  \"dataQuality\": true,\n",
    "  \"describedBy\": \"http://www.data.gov/metric\",\n",
    "  \"describedByType\": \"text/csv\",\n",
    "  \"issued\": \"2013-05-13\",\n",
    "  \"license\": \"https://creativecommons.org/publicdomain/zero/1.0/\",\n",
    "  \"spatial\": \"United States\",\n",
    "  \"publisher\": {\n",
    "      \"@type\": \"org:Organization\",\n",
    "      \"name\": \"General Services Administration\"\n",
    "  },\n",
    "  \"accrualPeriodicity\": \"R/P1M\",\n",
    "  \"isPartOf\": \"GSA-2015-09-14-01\",\n",
    "  \"contactPoint\": {\n",
    "      \"@type\": \"vcard:Contact\",\n",
    "      \"fn\": \"Hyon Joo Kim\",\n",
    "      \"hasEmail\": \"mailto:hyon.kim@gsa.gov\"\n",
    "  },\n",
    "  \"distribution\": [{\n",
    "          \"@type\": \"dcat:Distribution\",\n",
    "          \"mediaType\": \"text/csv\",\n",
    "          \"format\": \"text/csv\",\n",
    "          \"title\": \"Data.gov_Top_10_Visiting_Countries.csv\",\n",
    "          \"downloadURL\": \"https://inventory.data.gov/dataset/b0d40da1-a505-476a-a49b-cfc50ea6d9da/resource/0a1a3fb8-a813-4470-b50c-51b7856203be/download/userssharedsdfdata.govtop10visitingcountries.csv\"\n",
    "      }\n",
    "  ],\n",
    "  \"keyword\": [\"Countries\", \"Interactive\"],\n",
    "  \"bureauCode\": [\"023:00\"],\n",
    "  \"programCode\": [\"023:019\"],\n",
    "  \"language\": [\"us-EN\"],\n",
    "  \"theme\": [\"Countries\", \"Top 10\"]\n",
    "  }\n",
    "\n",
    "Answer: The \"accessLevel\" field says \"public\" so pii is False.\n",
    "The \"modified\" field is \"2016-01-20\". The current year is 2023, 2023 minus 16 is 7, so the age is 8.\n",
    "To determine keywords I will look at all the fields that describe the dataset.\n",
    "Then I will take the most salient and distinctive aspects of the fields and make those keywords.\n",
    "Looking at all the fields, the ones that describe the dataset are  \"description\" and \"title\".\n",
    "The \"title\" field is \"Data.gov Top 10 Visiting Countries - Archival\".\n",
    "Good keywords from the \"title\" field are \"data.gov\", \"top 10\".\n",
    "The \"description\" field is \"This dataset provides top 10 visiting countries by month in Data.gov up to July 2013.\"\n",
    "Good keywords from the \"description\" field are \"top 10\" and \"visiting countries\".\n",
    "Good proposed keywords from both fields are \"data.gov\", \"top 10\", and \"visiting countries\".\n",
    "Next inspect the \"keyword\" field to make sure the proposed keywords are not already included.\n",
    "The \"keyword\" field contains the keywords \"Countries\" and \"Interactive\"\n",
    "None of the proposed keywords are in the \"keyword\" field.\n",
    "\"data.gov\", \"top 10\", and \"visiting countries\" are all acceptable new keywords.\n",
    "\n",
    "Output JSON:\n",
    "{\n",
    "  \"pii\" : false,\n",
    "  \"age\" : 9,\n",
    "  \"keywords\" : [\"data.gov\", \"top 10\", \"visiting countries\"]\n",
    "}\n",
    "\"\"\"\n",
    "llm_call = f\"{context}{few_shot_exemplar}\\nJSON:{question}\\nAnswer:\"\n",
    "_ = call_llm(model, parameters, llm_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wY8sKdk9fN3Z",
    "tags": []
   },
   "source": [
    "## Self-Consistency\n",
    "\n",
    "Self-Consistency is a technique to improve the performance of chain of thought prompts--you make the same LLM call multiple times and take the most common answer.\n",
    "\n",
    "This means \"breaking\" the rule to use chain of thought with temperature=0.\n",
    "\n",
    "The intuition behind self-consistency is:\n",
    "1. Multiple responses to identical LLM calls means a variety of reasoning paths in the responses.\n",
    "1. Incorrect reasoning paths lead to different incorrect answers.\n",
    "1. Correct reasoning paths lead to the same correct answer.\n",
    "1. While you may only get a few correct answers and many incorrect answers, the correct answer will be more common than any unique incorrect answer.\n",
    "\n",
    "Let's try self-consistency. First, run this next LLM call with temperature 0 to generate an incorrect response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 798
    },
    "id": "pYKVZ8iHhf1d",
    "outputId": "5fb368bd-ad86-47e6-a643-cb9bf840eb1d"
   },
   "outputs": [],
   "source": [
    "# The answer is 1300 + 100 (maintenance) + 75 (upgrade) = 1475.\n",
    "question = \"\"\"Factories have a baseline productivity of 100 units per day.\n",
    "Not all factories have the baseline productivity.\n",
    "When a factory is being upgraded, it has 25% of the baseline productivity.\n",
    "When a factory is undergoing maintenance, it has 50% of the baseline.\n",
    "When a factory is under labor action, it produces nothing.\n",
    "Megacorp has 19 factories in total.\n",
    "3 factories are being upgraded.\n",
    "2 factories are under maintenance.\n",
    "1 is under labor action.\n",
    "How many units does megacorp produce in a day?\"\"\"\n",
    "\n",
    "context = \"\"\"Answer questions showing the full math and reasoning.\n",
    "Follow the pattern in the example.\n",
    "\"\"\"\n",
    "\n",
    "one_shot_exemplar = \"\"\"Q: A regular tennis ball can holds 5 balls.\n",
    "A large tennis ball can holds 200% of a regular tennis ball can.\n",
    "A small tennis ball can holds 40% of a regular tennis ball can.\n",
    "A collectable tennis ball can holds no tennis balls.\n",
    "Roger has 10 tennis ball cans.\n",
    "3 cans are large cans.\n",
    "4 cans are small cans.\n",
    "1 can is collectable.\n",
    "How many tennis balls does Roger have?\n",
    "A: We need to find the number of regular tennis ball cans.\n",
    "Roger has 10 (total) - 3 (large) - 4 (small) - 1 (collectable) = 2 regular cans.\n",
    "A large tennis ball can holds 200% of 5 = 10 tennis balls.\n",
    "A small tennis ball can holds 40% of 5 = 2 tennis balls.\n",
    "Next count how many balls come from each can type.\n",
    "3 large cans is 3 * 10 = 30 tennis balls.\n",
    "4 small cans is 2 * 4 = 8 tennis balls.\n",
    "2 regular cans is 2 * 5 = 10 tennis balls\n",
    "1 collectable can is 0 tennis balls.\n",
    "To get the answer, add the number of balls from each can type.\n",
    "Roger has 30 (large) + 8 (small) + 10 (regular) + 0 (collectable) = 48 balls.\n",
    "The answer is 48.\n",
    "\n",
    "Q: \"\"\"\n",
    "\n",
    "llm_call = f\"{context}\\n{one_shot_exemplar}{question}\\nA:\"\n",
    "_ = call_llm(model, parameters, llm_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BfyjnV8Clxia"
   },
   "source": [
    "Next, increase `temperature` to .7 and use high `top_p` and `top_k` values to generate a different response.\n",
    "\n",
    "Run the next cell a few times and note how the answer changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 798
    },
    "id": "Fqr8DxNylcC1",
    "outputId": "b229260d-e5cc-448d-cf98-4f4933e12e73"
   },
   "outputs": [],
   "source": [
    "sc_parameters = {\n",
    "    \"temperature\": .7,\n",
    "    \"max_output_tokens\": 512,\n",
    "    \"top_p\": 1,\n",
    "    \"top_k\": 40\n",
    "}\n",
    "\n",
    "_ = call_llm(model, sc_parameters, llm_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QrbTQUGymnUr"
   },
   "source": [
    "As you rerun the code above, you'll see a variety of reasonings and answers.\n",
    "\n",
    "Next, loop and generate many responses, extract the answers, then output the answers from most to least common.\n",
    "\n",
    "This takes a few minutes to run. While it runs note the variety of reasonings and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5L1KRC6Hm5Ir",
    "outputId": "1ba863a2-dca1-46a8-88a1-bc31f3fc6b98"
   },
   "outputs": [],
   "source": [
    "from collections import Counter  # Easy counting of most common responses.\n",
    "sc_runs = 40\n",
    "responses = [None] * sc_runs\n",
    "answers = [None] * sc_runs\n",
    "\n",
    "for i in range(0, sc_runs):\n",
    "  print(f\"Response {i}...\")\n",
    "  responses[i] = call_llm(model,\n",
    "                          sc_parameters,\n",
    "                          llm_call,\n",
    "                          # Turn off printing LLM calls/responses.\n",
    "                          show_activity=False)\n",
    "  # If the response doesn't contain 'The answer is', the split fails.\n",
    "  # The split also fails if the answer contains a decimal or comma.\n",
    "  try:\n",
    "    answers[i] = responses[i].split(\"The answer is\")[1].split(\".\")[0].strip()\n",
    "  except Exception as e:\n",
    "    answers[i] = \"NA\"\n",
    "  print(responses[i])\n",
    "print(\"Answers and counts from most common to least common:\")\n",
    "print(Counter(answers).most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxZ2S8hd9f33"
   },
   "source": [
    "The last output from the cell above is the counts of different answers. The correct answer (1475) should come back as the most common answer.\n",
    "\n",
    "The more LLM calls made, the greater the likelihood the most common answer is the correct answer.\n",
    "\n",
    "We can also plot the results to visualize the distribution of answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "id": "OfJiXg_qWB0A",
    "outputId": "0ff21362-6f2d-4ae5-87d5-2ff400144d5b"
   },
   "outputs": [],
   "source": [
    "# Thanks to Hans-Christian Fuchs for this.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(Counter(answers).keys(), Counter(answers).values())\n",
    "ax.tick_params(axis='x', rotation=55)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyMEmx1J_osN"
   },
   "source": [
    "### Self-Consistency Advantages\n",
    "\n",
    "1. Low-effort performance boost.\n",
    "1. Helps ideate chain-of-thought exemplars.\n",
    "1. Increased prompt robustness across different LLMs.\n",
    "1. Provides a pseudo \"confidence\" estimate based on the answer distributions.\n",
    "1. Opportunities to use \"average\" answers for problems without a single correct answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NsaFThs-_pyG"
   },
   "source": [
    "### Self-Consistency Disadvantages\n",
    "\n",
    "1. Increased costs.\n",
    "1. Slower inference time and/or reduced throughput.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ov281oL--eRh"
   },
   "source": [
    "### Self-Consistency Best Practices\n",
    "\n",
    "1. **Do** Use `temperature=.7`, `top_k=40`, `top_p=1`, and 10 responses as a starting point.\n",
    " * **Do** Experiment from there, different use cases may need different values.\n",
    " * **Do** Find optimal values for production use cases by conducting a hyperparameter search.\n",
    "   * Note that it's likely much more valuable to search on the response count than the LLM parameters, and if you do experiment with LLM parameters it's usually not worth reducing them much.\n",
    "1. **Do** Try self-consistency early if your initial prompt engineering attempts fail.\n",
    " * Self-consistency is more likely to boost performance than continuing to engineer your chain of thought prompt.  \n",
    "1. **Don't** Ignore cost and latency implications.\n",
    "1. **Do** Parallelize LLM calls to reduce execution time.\n",
    " * **Don't** Put off assessing the LLM throughput and latency your self-consistency use case requires.\n",
    "1. **Do** Use response distributions in creative ways. For example:\n",
    " * If fewer than X percent of answers match, flag the question for human review.\n",
    " * Generate multiple summaries and use a text similarity metric to identify which generated summary is most \"average\".\n",
    "1. **Do** Use self-consistency to inspire few-shot exemplars and to debug your prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PC4l5oHtD9OO",
    "outputId": "7da83524-a7ee-4374-b7ad-a41a60ad282e"
   },
   "outputs": [],
   "source": [
    "step_one_call = f\"\"\"{context}\n",
    "\n",
    "{exemplar}\n",
    "\n",
    "Question: {question}\n",
    "Wikipedia Search:\"\"\"\n",
    "step_one_response = call_llm(model, parameters, step_one_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "_2cqh5R4HTHV",
    "outputId": "171799dc-f330-4389-8aa9-18fedf17089c"
   },
   "outputs": [],
   "source": [
    "def get_wiki_query (llm_response, stop_text = \"<STOP>\"):\n",
    "  # Assumes the query is in the first line.\n",
    "  first_line = llm_response.splitlines()[0]\n",
    "  query = first_line.split(stop_text)[0]\n",
    "  return query.strip() # Remove leading and trailing whitespace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sv6ox89JYPe"
   },
   "source": [
    "Use this function on the response from the previous LLM call to extract the query, then  use `wiki_tool` to search Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "id": "0d5CKJRyJW5C",
    "outputId": "03d81998-97cd-4332-dfb0-c2666b4f188a"
   },
   "outputs": [],
   "source": [
    "wiki_query = get_wiki_query(step_one_response)\n",
    "print(f\"Tool Query: {wiki_query}\")\n",
    "wiki_text = wiki_tool(wiki_query)\n",
    "print(f\"Wikipedia Snippet: {wiki_text}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m111"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
